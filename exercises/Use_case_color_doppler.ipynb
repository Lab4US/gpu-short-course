{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d68ca6e-2fb1-46b7-a6f5-de9cc76cb7c7",
   "metadata": {},
   "source": [
    "## A (very) brief introduction to Color Doppler "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89155fcf-6b66-4d22-98c2-fc532e089ed6",
   "metadata": {},
   "source": [
    "Color doppler is a medical imaging modality for blood flow imaging.  \n",
    "It bases on the Doppler effect that is a shift of a received signal frequency, when the wave source is moving relatively to the receiver.  \n",
    "In medicine, 'sources' (i.e. moving tissue, specifically blood) do not emit acoustic waves, but are 'iluminated' by ultrasound pulses produced by a probe.  \n",
    "It can be shown [Evans2000] that the shift in the received frequency is given by following equation:\n",
    "\n",
    "$$\n",
    "f_d = f_t - f_r = \\frac{2f_tv\\cos{\\alpha}}{c}\n",
    "$$\n",
    "\n",
    "where\n",
    "* $f_d$ - frequency shift, or doppler frequency,\n",
    "* $f_t$ - transmitted frequency, \n",
    "* $f_r$ - received frequency, \n",
    "* $v$ - speed of the blood,\n",
    "* $\\alpha$ - the angle between the ultrasound beam and the direction of motion of the blood,\n",
    "* $c$ - speed of sound in the medium. It is usually assumed that in soft tissue $c = 1540 [m/s]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a5dc72-78b1-455e-8a54-5cceaf467bbb",
   "metadata": {},
   "source": [
    "<!-- When the medical probe transmits the ultrasound pulse, and it is scattered on moving blood (i.e. on blood cells), the received echoes changes in phase.    -->\n",
    "In classical approach the probe transmits a series of (quite long) ultrasound pulses, receiving echoes after each transmit.  \n",
    "The series consists of $N$ transmit/receive (TR) events, and the higher $N$, the higher sensitivity, but lower doppler framerate.  \n",
    "Typically $N$ could be in the range of $8-16$ for classical methods and $32-256$ for synthetic aperture methods, however there are no strict rules.  \n",
    "The TR events in the series are repeated with constant Pulse Repetition Frequency (PRF).  \n",
    "Thus the time between TR events - Pulse Repetition Interval (PRI) is equal $\\frac{1}{PRF}$.  \n",
    "The received signals are IQ demodulated and reconstructed into IQ images.   Then, the high-pass filter in 'slow time' (the so-called wall clutter filter) is used.  \n",
    "This filter is used for removing the constant echoes coming from non-flowing medium.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d08567e-05d4-4c84-b58a-4c7e1657ec52",
   "metadata": {},
   "source": [
    "## Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd33ffe-6da9-4ed2-83f6-362dbbcb2f94",
   "metadata": {},
   "source": [
    "The $f_d$ can be estimated from high-pass filtered IQ signal by means of autocorrelation esitmator:  \n",
    "\n",
    "$$\n",
    "\\overline{f_d} = \\frac{1}{2\\pi{}PRI} \n",
    "    \\tan^{-1}{\\left\\{ \n",
    "        \\frac{\\sum^{N}_{i=1}{Q(i)I(i-1) - I(i)Q(i-1)}}\n",
    "             {\\sum^{N}_{i=1}{I(i)I(i-1) + Q(i)Q(i-1)}}\n",
    "    \\right\\}}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "<!-- , and next the phase is estimated for each sample.  \n",
    "Then, for each sample the phase changes $\\Delta{\\theta}$ from TR to TR are calculated. Sometimes it is refered as phase changes in 'slow time'.  \n",
    "The doppler frequency (averaged over time) can be calculated from the formula\n",
    "\n",
    "$$\n",
    "\\overline{f_d} = \\frac{1}{N-1} \\sum_{n=1}^{N-1} \\frac{\\Delta{\\theta}_{n}}{PRI}\n",
    "$$\n",
    "\n",
    " -->\n",
    "Then, we can use the following formula to estimate average speed of the blood flow.  \n",
    "\n",
    "$$\n",
    "v_s = \\frac{\\overline{f_d}}{f_t} \\frac{c}{2\\cos{\\alpha}}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The second mode used in medical flow imaging is power doppler, i.e. the power of the doppler signal.  \n",
    "The power $p$ can be estimated using following estimator:\n",
    "\n",
    "$$\n",
    "p = \\sum^{N}_{i=1}{I(i)I(i) + Q(i)Q(i)}\n",
    "$$\n",
    "\n",
    "The $p$ will be used to create a mask when displaying the flow - only those areas with adequate doppler signal strength will be displayed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f4845f-7d0b-41f5-a193-98cdba55bdfd",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b26ba76-ce2b-4caa-bfc4-ca7dd6a6f5da",
   "metadata": {},
   "source": [
    "## Let's implement above estimators in GPU kernel, use it, and show some doppler images.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616de791-e59b-4f1b-b1df-804b4b9431b6",
   "metadata": {},
   "source": [
    "In this and the following notebooks, we will use the tools, tests and benchmarks available in the gpu_short_course Python package, which can be found in the repository https://github.com/us4useu/ius-2021-gpu-short-course. Please run the below line before proceeding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7030861a-ae2a-4d3e-840d-053ac12a5750",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade --force-reinstall -q git+https://github.com/us4useu/ius-2021-gpu-short-course@develop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48db7a9e-8f17-4e7c-8ebf-72a57830fd4c",
   "metadata": {},
   "source": [
    "### 'import' section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93ec66ba-e0bb-4dcf-964d-bf1e0f60e263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU:0: b'GeForce RTX 3060 Laptop GPU'\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "import numpy as np\n",
    "import scipy.signal as spsig\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "from gpu_short_course.ultrasound_imaging import (\n",
    "    dB,\n",
    "    filter_wall_clutter_gpu,\n",
    "    iq2bmode_gpu,\n",
    "    show_flow,    \n",
    "    show_flow_cineloop,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c9813c7-e9d1-46ce-b0ce-2f2571676500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IoffContext at 0x7f5a6c2f8790>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cfg\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4270620d-efab-4120-84c1-f0af3f8105b0",
   "metadata": {},
   "source": [
    "### Kernel definition\n",
    "The following kernel estimate both (non-scaled) doppler frequency (i.e. $\\overline{f_d} \\cdot{}2\\pi{}PRI $) and the power $p$.  \n",
    "Since similar data is used to estimate both, this is more optimal than creating two separate kernels.    \n",
    "The kernel estimates doppler frames from IQ array.   \n",
    "The IQ array is divided into batches (subsets) consisting of the same number of frames.   \n",
    "Each doppler frame is estimated from a batch.   \n",
    "The first frames in subsequent batches are separated by a fixed number of frames - 'step'. \n",
    "Thus, the batches can overlap.   \n",
    "\n",
    "The kernel use following parameters:\n",
    "* float *color - pointer to output array for color data,\n",
    "* float *power - pointer to output array for power data,\n",
    "* const complex\\<float\\> *iqFrames - pointer to input IQ array (I is in real part, Q is in imaginary part),\n",
    "* const nBatch - number of batches\n",
    "* const nBatchFrames - number of frames in single batch,\n",
    "* const nx - number of columns in IQ data frame,\n",
    "* const nz - number of samples in IQ data frame (it is common convention in the field to use 'z' axis for depth)\n",
    "* const step - 'distance' (in [frames]) between the batches,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bdd045f-0c3a-47a9-95f2-1f3d3715dab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_source = r\"\"\"\n",
    "\n",
    "#include <cupy/complex.cuh>\n",
    "extern \"C\" __global__ \n",
    "void doppler(float *color, \n",
    "             float *power, \n",
    "             const complex<float> *iqFrames, \n",
    "             const int nBatch, \n",
    "             const int nBatchFrames,             \n",
    "             const int nx, \n",
    "             const int nz, \n",
    "             const int step)\n",
    "                  \n",
    "{\n",
    "    int z = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int x = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    int t = blockIdx.z * blockDim.z + threadIdx.z;\n",
    "    \n",
    "    if (z >= nz || x >= nx || t >= nBatch) {\n",
    "        return;\n",
    "    }\n",
    "    \n",
    "    /* Color and Power estimation */\n",
    "        \n",
    "    complex<float> iqCurrent, iqPrevious;\n",
    "    float ic, qc, ip, qp, pwr, nom = 0.0f, den = 0.0f;\n",
    "\n",
    "    iqCurrent = iqFrames[z + x*nz + t*nx*nz*step];\n",
    "    ic = real(iqCurrent);\n",
    "    qc = imag(iqCurrent);\n",
    "    pwr = ic*ic + qc*qc;\n",
    "    \n",
    "    for (int iFrame = 1; iFrame < nBatchFrames; iFrame++) {\n",
    "        // previous I and Q values\n",
    "        ip = ic;\n",
    "        qp = qc;\n",
    "        \n",
    "        // current I and Q values\n",
    "        iqCurrent = iqFrames[z + x*nz + t*nx*nz*step + iFrame*nz*nx];\n",
    "        ic = real(iqCurrent);\n",
    "        qc = imag(iqCurrent);\n",
    "        \n",
    "        pwr += ic*ic + qc*qc;\n",
    "        den += ic*ip + qc*qp;\n",
    "        nom += qc*ip - ic*qp;\n",
    "    }\n",
    "    color[z + x*nz + t*nx*nz] = atan2f(nom, den);\n",
    "    power[z + x*nz + t*nx*nz] = pwr/nBatchFrames;\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "doppler = cp.RawKernel(cuda_source, 'doppler')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a7dd84-cb32-45bd-b170-8c9a7bcb2110",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b45ae91-e554-44c5-a206-2c4b3059c001",
   "metadata": {},
   "source": [
    "These 512 IQ images were acquired from radial artery of healthy volunteer.  \n",
    "The single plane wave imaging (PWI) scheme was used for each image.  \n",
    "Transmit angle was 20 degree, and receive angle was equal 0 degree.   \n",
    "The illustrative image below show the vessel as a darker region between 3-5 mm depth.   \n",
    "<!-- ![title](data/bmode.jpg) -->\n",
    "\n",
    "<img src=\"data/bmode.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83f0b8f5-65eb-4ffe-9cff-7eabf0af8c1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/example_doppler_data.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7607/1718870897.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/example_doppler_data.npz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0miq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"iq\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# frames of IQ data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mxgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"xgrid\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# vector of 'x' coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mzgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"zgrid\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# vector of 'z' coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prf\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# pulse repetition frequency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/arrus/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/example_doppler_data.npz'"
     ]
    }
   ],
   "source": [
    "data = np.load(\"data/example_doppler_data.npz\")\n",
    "iq = data[\"iq\"] # frames of IQ data\n",
    "xgrid = data[\"xgrid\"] # vector of 'x' coordinates\n",
    "zgrid = data[\"zgrid\"] # vector of 'z' coordinates\n",
    "prf = data[\"prf\"] # pulse repetition frequency\n",
    "c = data[\"c\"] # speed of sound\n",
    "tx_frequency = data[\"tx_frequency\"] # transmit frequency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c671ad0-e011-4fa9-8d01-8b1ba7cd23b2",
   "metadata": {},
   "source": [
    "### Color doppler estimation using defined kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b683c90-3918-43da-b79f-0f3c52188310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# push iq data into gpu\n",
    "iq_gpu = cp.array(iq)\n",
    "\n",
    "# apply wall clutter filter\n",
    "iq_wcfilt = filter_wall_clutter_gpu(iq_gpu, Wn=0.19, N=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340dee79-0feb-400e-9f7e-8f7968a767a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nframes, nx, nz = iq_wcfilt.shape\n",
    "\n",
    "# set the number of frames in a batch, and step batches\n",
    "nbatchframes = 256 \n",
    "step = 8\n",
    "\n",
    "# calculate number of batches \n",
    "nstep = np.floor((nframes - nbatchframes)/step).astype(int)\n",
    "nbatch = nstep + 1\n",
    "\n",
    "# specify block and grid sizes\n",
    "bx = 16\n",
    "bz = 16\n",
    "bt = 4\n",
    "gx = np.ceil(nx/bx).astype(int)\n",
    "gz = np.ceil(nz/bx).astype(int)\n",
    "gt = np.ceil(nbatch/bt).astype(int)\n",
    "block = (bz, bx, bt)\n",
    "grid = (gz, gx, gt)\n",
    "\n",
    "# allocate memory on gpu for output data\n",
    "color =  cp.zeros((nbatch, nx, nz)).astype(cp.float32)\n",
    "power =  cp.zeros((nbatch, nx, nz)).astype(cp.float32)\n",
    "\n",
    "# use kernel \n",
    "doppler(grid, block, (color, power, iq_wcfilt, nbatch, nbatchframes, nx, nz, step))\n",
    "\n",
    "# transpose data to (samples, columns, frames) order, and get data from gpu \n",
    "color = color.T.get()\n",
    "power = power.T.get()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22f6492-feec-4a45-a7eb-5e2376456b5d",
   "metadata": {},
   "source": [
    "### color scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef0588d-bddc-461a-8053-430ef4ddf9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The transmit angle was 20deg, receive angle was 0deg - lets assume 10deg effective angle\n",
    "alpha = 10/180*np.pi\n",
    "\n",
    "# doppler frequency\n",
    "fd = prf/2/np.pi*color # [Hz]\n",
    "\n",
    "# blood speed\n",
    "v = fd/tx_frequency*c/2/np.cos(alpha)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043bbd64-6922-4017-be3d-134c0eab1609",
   "metadata": {},
   "source": [
    "### Calculate B-mode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1567605-4caa-4c73-b0e2-ac0d7393987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make b-mode arrays from non-filtered iq data,  and get it from gpu.\n",
    "# Each b-mode sub-array (bmode[:,:,i]) corresponds to data from the center of each batch.\n",
    "bmode = np.zeros_like(color)\n",
    "batch_center_frame = np.round(nbatchframes/2).astype(int)\n",
    "for ibatch in range(nbatch):\n",
    "    iframe = ibatch*step + batch_center_frame\n",
    "    bmode[:,:,ibatch] = iq2bmode_gpu(iq_gpu[iframe,:,:]).T.get()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dbafbc-2cfa-4453-ae9d-6241a3955151",
   "metadata": {},
   "source": [
    "### Presentation of results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c88e366-7664-400b-8e92-e55bca616110",
   "metadata": {},
   "source": [
    "#### show single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e6c18b-9933-4444-aa77-cfa7e09c0981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make b-mode array from non-filtered iq data and get it from gpu\n",
    "ibatch = 0\n",
    "if ibatch > nbatch:\n",
    "    raise ValueError(f\"ibatch ({ibatch}) must be  less than or equal nbatch ({nbatch})\")\n",
    "\n",
    "# set parameters for show_flow() function\n",
    "doppler_type = \"speed\"\n",
    "# doppler_type = \"power\"\n",
    "# doppler_type = \"doppler frequency\"\n",
    "# doppler_type = \"color\"\n",
    "\n",
    "bmode_limit = (-40, 0)\n",
    "power_limit = (26, 56)\n",
    "if doppler_type == \"speed\":\n",
    "    cdata = v[:,:,ibatch] \n",
    "    \n",
    "elif  doppler_type == \"power\":\n",
    "    cdata = []\n",
    "\n",
    "elif  doppler_type == \"doppler frequency\":\n",
    "    cdata = fd[:,:,ibatch]\n",
    "\n",
    "elif  doppler_type == \"color\":\n",
    "    cdata = color[:,:,ibatch]\n",
    "\n",
    "# final image\n",
    "show_flow(\n",
    "    bmode[:,:,ibatch], \n",
    "    cdata, \n",
    "    dB(power[:,:,ibatch]), \n",
    "    xgrid, zgrid,\n",
    "    doppler_type=doppler_type,\n",
    "    power_limit=power_limit,\n",
    "    bmode_limit=bmode_limit)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9496387-198c-4988-ae9a-981c1981624d",
   "metadata": {},
   "source": [
    "#### show animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cbc9de-9144-46c4-8d40-6b2009777f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "doppler_type = \"speed\"\n",
    "# doppler_type = \"power\"\n",
    "# doppler_type = \"doppler frequency\"\n",
    "# doppler_type = \"color\"\n",
    "\n",
    "bmode_limit = (-40, 0)\n",
    "power_limit = (26, 56)\n",
    "if doppler_type == \"speed\":\n",
    "    cdata = v\n",
    "    \n",
    "elif  doppler_type == \"power\":\n",
    "    cdata = []\n",
    "\n",
    "elif  doppler_type == \"doppler frequency\":\n",
    "    cdata = fd\n",
    "\n",
    "elif  doppler_type == \"color\":\n",
    "    cdata = color\n",
    "\n",
    "anim = show_flow_cineloop(\n",
    "    bmode, \n",
    "    cdata, \n",
    "    dB(power),\n",
    "    xgrid=xgrid,\n",
    "    zgrid=zgrid,\n",
    "    doppler_type=doppler_type,\n",
    "    power_limit=power_limit,\n",
    "    bmode_limit=bmode_limit)\n",
    "\n",
    "HTML(anim.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db63cd0-6522-4fce-a119-ebc0afb3a552",
   "metadata": {},
   "source": [
    "-----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef67158-693a-4419-bf02-2838f4bbce9e",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8ab8bb-add9-4175-8f20-31fb373b1790",
   "metadata": {},
   "source": [
    "[Evans2000] Evans, David H., and W. Norman McDicken. Doppler ultrasound: physics, instrumentation and signal processing. Wiley-Blackwell, 2000."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
